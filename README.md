
# Image Captioning using VGG16 and LSTM

This is a baseline model for image captioning using VGG16 architecture and LSTM.


## Model

**Drive link:** https://drive.google.com/file/d/1T70eB-0nN_Zd1DsEbVXkFM5CEqCwWpIg/view?usp=share_link

## Dataset
**Flickr8k:** https://www.kaggle.com/datasets/aladdinpersson/flickr8kimagescaptions

## Features

- VGG16
- LSTM
- Word Embedding and Tokenizing
- Flickr8k datatset with 8000+ images with captions



## Some Examples

- Example 1

![](https://images.squarespace-cdn.com/content/v1/5ebb0ca06dde6c0448082d3d/1597551632467-WIXIRTQOEE9Y5BK93R4Y/two-puppies-starting-to-play.jpg)

Predicted : **dog jumps over hurdle** (detects dog and movement)

- Example 2
![](https://cdn.ndtv.com/tech/gadgets/fifa_16_freekick_EA.jpg)

Predicted : **two men are playing soccer**
- Example 2 (poor performance)
![](https://www.outlookindia.com/outlooktraveller/public/uploads/articles/explore/driving-holiday.jpg)

Predicted : **man in blue shirt and black pants is jogging down the road** (umm...more improvemnets required tho)
